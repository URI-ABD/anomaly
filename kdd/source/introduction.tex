\section{Introduction}
\label{sec:introduction}

Anomaly detection is difficult.
To determine if something deviates from normal, one must understand the normal, the abnormal, and the boundary between the two.

Normal data in the real-world are generated by some constrained generating phenomena.
Examples include:
\begin{itemize}
    \item biological evolution.
    \item stellar evolution.
    \item drug synthesis.
    \item network interactions.
\end{itemize}

Abnormal instances of data, which can be called \textit{outliers} or \textit{anomalies}, arise from such varied sources as:
\begin{itemize}
    \item errors in measurements and data collection.
    \item noise in data mimicking real outliers.
    \item blurry boundaries between abnormal and normal behaviour.
    \item normal behaviour evolving into abnormal behaviour.
    \item novel never-before-seen instances in data.
    \item adversarial attacks.
\end{itemize}

In this paper, we tackle this challenge using a novel Manifold Learning technique.
% TODO: and compare our performance against oft-used state-of-the-art anomaly-detection techniques.
We use CHESS~\cite{ishaq2019entropy} to build a clustering on the data.
We then build a graph from the leaf-clusters by creating edges between clusters that have overlapping volumes.
This process effectively learns the manifold that the data lie on.
Once we have learned a manifold, an anomaly is simply a point which does not fall on that manifold.

We test our methods on several synthetic datasets. These datasets all have the quality that the data occupy a non-linear, low-dimensional manifold in a high-dimensional embedding space.

We consider several different definitions for outliers and anomalies.
\begin{itemize}
    \item Since CHESS produces a distance-based clustering, we adapt several classical distance-based definitions of outliers.
    \item Since we have a clustering on our data, we can consider sparsely populated clusters to contain anomalies, thereby leveraging density-based definitions of outliers.
    \item Since we have a graph on our data, we have access to several graph-based methods for anomaly detection.
    \item Since search time is independent of the size of size of the data, we can use our method for novelty detection in streams of new data.
    \item Since the clustering can be live-updated, we can adapt to changing behaviour in new data.
\end{itemize}

All forms of clustering hitherto have suffered from one defect or another.
The most common deficiencies are: the effective treatment of high dimensionality, interpretability of results, and/or scalability to exponentially growing datasets ~\cite{rakesh_agrawal_automatic_1998}.
With CHESS, we have largely alleviate these problems while also uncoupling search-time from the size of the data being searched.
By defining edges via cluster-overlap, we build a graph representation of the manifold that the data occupy.
We use our knowledge of this manifold to guide the detection of anomalies, outliers and novelties.

% TODO: Add definitions: Anomaly, Outlier, Novelty, etc.
