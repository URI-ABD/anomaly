\section{Methodology}
\label{sec:methodology}

Given the manifold and induced graph produced by CLAM (described in Section~\ref{introduction:chaoda}), we have implemented five distinct algorithms for detecting anomalies or outliers, all of which take advantage of either the hierarchical nature of the cluster-tree or the graph from a layer of clusters at a given depth.


\subsection{Cluster Cardinality}

For this method we equate anomalousness with the cardinality of the cluster to which a point belongs.
If a point belongs to a cluster with a very small number of points, it is more likely that the point is an anomaly or an outlier.
Clusters that have a large cardinality are treated as more likely to contain normal points.
Algorithm~\ref{alg-cc} details the cluster cardinality approach.

\begin{algorithm}
\DontPrintSemicolon
\SetAlgoLined
\KwData{manifold, depth}
\KwResult{scores}
 $scores \leftarrow \{\}$\;
 $d \leftarrow depth$\;
 \ForAll{cluster $c \in$ manifold.graph(d).clusters}{
  \ForAll{$p \in c.points$}{
   $scores[p] \leftarrow |c|$
  }
 }
 normalize(scores)\;
 \ForAll{$p \in scores$}{$scores[p] \leftarrow 1-p$}
 \caption{Cluster Cardinality}
 \label{alg-cc}
\end{algorithm}

\subsection{Parent-Child}

In this approach, we examine the ratio of the cardinality of a cluster with that of its parent.
For a given depth of the tree, a point is considered to be more anomalous if the cluster it belongs to is significantly smaller than its parent.
This relationship tries to capture the intuition that those points which live far away from the manifold should fall into increasingly smaller clusters as the data is partitioned.
This approach is detailed in Algorithm~\ref{alg-pc}.

\begin{algorithm}
\DontPrintSemicolon
\SetAlgoLined
\KwData{manifold,depth}
\KwResult{scores}
 $scores \leftarrow \{\}$\;
 $d \leftarrow depth$\;
 \For{$d \in 1\cdots$ depth}{
  \ForAll{cluster $c \in $manifold.graph(d).clusters}{
    \ForAll{point $p \in c$}{
     $scores[p] \leftarrow \frac{|c.parent|}{|c|\times d}$
    }
  }
 }
 normalize(scores)\;
 \caption{Parent-Child}
 \label{alg-pc}
\end{algorithm}

\subsection{k-Neighborhood}

For this approach, we rely on the graph induced by CLAM at a particular depth of the tree, as explained in Section~\ref{introduction:chaoda}.
Given that graph and a point we consider the number of clusters reachable within a graph distance of $k$ from the point's cluster.
The more clusters which are reachable from a given cluster, the \textit{less} likely it is to contain anomalous points.
This approach is detailed in Algorithm~\ref{alg-kneighborhood}

\begin{algorithm}
\DontPrintSemicolon
\SetAlgoLined
\KwData{manifold,depth,k}
\KwResult{scores}
 $scores \leftarrow \{\}$\;
 $d \leftarrow $ depth\;
 $g \leftarrow $ manifold.graph(d)\;
 \ForAll{cluster $c \in g$}{
  $v \leftarrow |\{c' \in g | \delta(c,c') \le k\}|$\;
  \ForAll{$p \in c$}{
   scores[p] $\leftarrow v$\;
  }
 }
 normalize(scores)\;
 \ForAll{$p \in scores$}{$scores[p] \leftarrow 1-p$}
 \caption{k-Neighborhood}
 \label{alg-kneighborhood}
\end{algorithm}

\subsection{Random Walk}

Here, we implement the Outrank~\cite{moonesinghe2008outrank} algorithm but with a key difference: since the graph induced by CLAM at a given depth of the tree may contain many disconnected components, some parts of the graph may be unreachable from any given cluster.
The general idea behind this approach is to examine the frequency with which clusters are visited during $n$ random walks.
Clusters that are visited more frequently are less likely to be anomalous.
Clusters that are not visited frequently are more likely to be disconnected and distant from the underlying manifold.
This approach is detailed in Algorithm~\ref{alg-rw}, which assumes that $outrank(k)$ returns a hash table whose keys are the clusters of the graph, and whose values are the number of visits by a random walk to each cluster.

\begin{algorithm}
\DontPrintSemicolon
\SetAlgoLined
\KwData{manifold,depth}
\KwResult{scores}
 $scores \leftarrow \{\}$\;
 $d \leftarrow $ depth\;
 $g \leftarrow $ manifold.graph(d).components\;
 \ForAll{component $k \in g$}{
  visits $\leftarrow$ outrank(k)\;
  \ForAll{cluster $c \in k$}{
   $v \leftarrow $visits[c]\;
   \ForAll{$p \in c$}{
    scores[p] $\leftarrow v$\;
   }
  }
 }
 normalize(scores)\;
 \ForAll{$p \in scores$}{$scores[p] \leftarrow 1-p$}
 \caption{Random Walk}
 \label{alg-rw}
\end{algorithm}

\subsection{Subgraph Cardinality}

This approach is similar to Cluster Cardinality.
Here,  we utilize the cardinality of each connected component of the graph at various depths to determine anomalousness.
As with some of our other approaches, we postulate that clusters which are members of sparse components are themselves more likely to be anomalous.
Algorithm~\ref{alg-sgc} details this approach.

\begin{algorithm}
\DontPrintSemicolon
\SetAlgoLined
\KwData{manifold, depth}
\KwResult{scores}
 $scores \leftarrow \{\}$\;
 $d \leftarrow depth$\;
 \ForAll{component $k \in$ manifold.graph(d).components}{
  \ForAll{cluster $c \in k$}{
   \ForAll{$p \in c$}{
    scores[p] $\leftarrow |k|$
   }
  }
 }
 normalize(scores)\;
 \ForAll{$p \in scores$}{$scores[p] \leftarrow 1-p$}
 \caption{Subgraph Cardinality}
 \label{alg-sgc}
\end{algorithm}

\subsection{Normalization}

Due to the wide range of possible measurements for ``anomalousness'' from our methods, we normalize our measurements using several different techniques.
We utilized Min-Max Scaling, shown in equation~\ref{sec:methods:min-max-normalizationn}, to ensure that anomalousness values are in the $[0, 1]$ range.
This lets us compare anomalousness of points fairly across our various methods.

\begin{gather}
x^{\prime} = \frac{x - x_{min}}{x_{max} - x_{min}}
\label{sec:methods:min-max-normalizationn}
\end{gather}
