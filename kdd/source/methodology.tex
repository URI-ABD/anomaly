\section{Methodology}
\label{sec:methodology}

For this work we have applied a multitude of different Distance-Based, Density-Based, and Graph-Based, approaches to detect anomalous and outlying points/clusters.
In this section, we detail the specific algorithms employed from these various categories.

\subsection{Distance-Based Outliers}

\begin{algorithm}
\DontPrintSemicolon
\SetAlgoLined
\KwData{manifold, depth}
\KwResult{scores}
 $scores \leftarrow \{\}$\;
 $d \leftarrow depth$\;
 \ForAll{cluster $c \in$ manifold.graph(d).clusters}{
  \ForAll{$p \in c.points$}{
   $scores[p] \leftarrow |c|$
  }
 }
 normalize(scores)\;
 \ForAll{$p \in scores$}{$scores[p] \leftarrow 1-p$}
 \caption{Cluster Cardinality}
 \label{alg-cc}
\end{algorithm}

\begin{algorithm}
\DontPrintSemicolon
\SetAlgoLined
\KwData{manifold,depth}
\KwResult{scores}
 $scores \leftarrow \{\}$\;
 $d \leftarrow depth$\;
 \For{$d \in 1\cdots$ depth}{
  \ForAll{cluster $c \in $manifold.graph(d).clusters}{
    \ForAll{point $p \in c$}{
     $scores[p] \leftarrow \frac{|c.parent|}{|c|\times d}$
    }
  }
 }
 normalize(scores)\;
 \caption{Hierarchical}
 \label{alg-hierarchical}
\end{algorithm}


\begin{algorithm}
\DontPrintSemicolon
\SetAlgoLined
\KwData{manifold,depth,k}
\KwResult{scores}
 $scores \leftarrow \{\}$\;
 $d \leftarrow $ depth\;
 $g \leftarrow $ manifold.graph(d).clusters\;
 \ForAll{cluster $c \in g$}{
  $v \leftarrow |\{c' \in g | \delta(c,c') \le k\}|$\;
  \ForAll{$p \in c$}{
   scores[p] $\leftarrow v$\;
  }
 }
 normalize(scores)\;
 \ForAll{$p \in scores$}{$scores[p] \leftarrow 1-p$}
 \caption{k-Neighborhood}
 \label{alg-kneighborhood}
\end{algorithm}


% Must cite outrank paper for this one

\begin{algorithm}
\DontPrintSemicolon
\SetAlgoLined
\KwData{manifold,depth}
\KwResult{scores}
 $scores \leftarrow \{\}$\;
 $d \leftarrow $ depth\;
 $g \leftarrow $ manifold.graph(d).components\;
 \ForAll{component $k \in g$}{
  visits $\leftarrow$ outrank(k)\;
  \ForAll{cluster $c \in k$}{
   $v \leftarrow $visits[c]\;
   \ForAll{$p \in c$}{
    scores[p] $\leftarrow v$\;
   }
  }
 }
 normalize(scores)\;
 \ForAll{$p \in scores$}{$scores[p] \leftarrow 1-p$}
 \caption{Random Walk}
 \label{alg-rw}
\end{algorithm}

\begin{algorithm}
\DontPrintSemicolon
\SetAlgoLined
\KwData{manifold, depth}
\KwResult{scores}
 $scores \leftarrow \{\}$\;
 $d \leftarrow depth$\;
 \ForAll{component $k \in$ manifold.graph(d).components}{
  \ForAll{cluster $c \in k$}{
   \ForAll{$p \in c$}{
    scores[p] $\leftarrow |k|$
   }
  }
 }
 normalize(scores)\;
 \ForAll{$p \in scores$}{$scores[p] \leftarrow 1-p$}
 \caption{Subgraph Cardinality}
 \label{alg-sgc}
\end{algorithm}

\begin{enumerate}
    \item Sort all points $p \in \mathbb{P}$, where $\mathbb{P}$ is the data, by $f \equiv |B_D(p, r)|$ in ascending order.
    \begin{itemize}
        \item If needed, increase $r$ to break ties.
        \item The points with the smallest values of $f$ are the outliers.
    \end{itemize}
    \item Sort all points $p \in \mathbb{P}$ in descending order by the distance to their $k^{th}$ nearest neighbor.
    \begin{itemize}
        \item Consider how this distance changes as $k$ in increased.
        \item The points with the highest such distances are the outliers.
    \end{itemize}
\end{enumerate}

\subsection{Hierarchical-Clustering-Based Outliers}

\begin{enumerate}
    \item For a $parent$ cluster and its $left$ and $right$ child-clusters (assume without loss of generality that $|left| \leq |right|)$ define $f \equiv \frac{|left|}{|parent|}$. If $f \ll 0.5$ then points in the $|left|$ cluster are outliers.
    \begin{itemize}
        \item Use this definition recursively down the tree. The number of levels in the tree at which a point is labelled an outlier gives us a measure of the ``anomalousness'' of that point.
    \end{itemize}
\end{enumerate}

\subsection{Graph-Based Outliers}

\begin{enumerate}
    \item The Outrank algorithm~\cite{moonesinghe_outrank:_2008} i.e. on a given graph-representation of data, initiate a random walk. The clusters that are visited least often are the outlier clusters.
    \item Define the ``k-neighborhood'' of a clusters $c$ as the clusters that can be reached from $c$ in $k$ steps. Investigate how $|k-neighborhood|$ increases as $k$ in increased.
    \begin{itemize}
        \item $|k-neighborhood|$ should increase by $k^d$ where $d$ is \textit{local fractal dimension} of the data at the length-scale of the radii of the clusters that form the graph.
        \item If the increase in $|k-neighborhood|$ of a cluster $c$ does not keep pace with $k^d$ as $k$ is increased then $c$ can be considered an outlier cluster.
    \end{itemize}
    \item Consider the connected components of the graph at a depth in the tree just before the graph shatters into many small components or isolated clusters.
    \begin{itemize}
        \item If a component contains too few points/clusters then those points/clusters can be considered outliers.
        \item If a small component is connected to a larger component with a small number of edges then the smaller component may contain outliers.
    \end{itemize}
\end{enumerate}

Due to the wide range of possible measurements for ``anomalousness'' from our methods, we normalize our measurements.

\subsection{Normalization Methods}

\begin{enumerate}
    \item Min-Max Scaling:
    \begin{gather}
        x^{\prime} = \frac{x - x_{min}}{x_{max} - x_{min}}
        \label{sec:methods:min-max-normalizationn}
    \end{gather}
    
    \item Mean-Scaling:
    \begin{gather}
        x^{\prime} = \frac{x - \overline{x}}{x_{max} - x_{min}}
        \label{sec:methods:mean-scaling}
    \end{gather}
    
    \item z-Score Standardization:
    \begin{gather}
        x^{\prime} = \frac{x - \overline{x}}{\sigma}
        \label{sec:methods:z-score}
    \end{gather}

\end{enumerate}
